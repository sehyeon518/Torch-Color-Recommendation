{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (72030, 2), version: 1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\datasets\\load.py:922: FutureWarning: The repository for Classification contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\\Classification.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(path=r\"C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\", split=\"train\")\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_data\", \"output_color\"], dtype=torch.float32)\n",
    "print(f\"data: {dataset.shape}, version: {dataset.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_size: 72030, valid_size: 0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 1.0)\n",
    "valid_size = total_size - train_size\n",
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
    "f\"train_size: {train_size}, valid_size: {valid_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 540\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "# valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_loader.__iter__().__next__()\n",
    "input_size = sample['input_data'].shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "weight_path = r\"C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\jsonl\\class_weight.jsonl\"\n",
    "with open(weight_path, 'r') as path:\n",
    "    class_weight = json.load(path)\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlifethis21\u001b[0m (\u001b[33mcolor_harmony\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\\wandb\\run-20240129_090616-gb3w5u96</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/color_harmony/color_harmony/runs/gb3w5u96' target=\"_blank\">astral-disco-35</a></strong> to <a href='https://wandb.ai/color_harmony/color_harmony' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/color_harmony/color_harmony' target=\"_blank\">https://wandb.ai/color_harmony/color_harmony</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/color_harmony/color_harmony/runs/gb3w5u96' target=\"_blank\">https://wandb.ai/color_harmony/color_harmony/runs/gb3w5u96</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/color_harmony/color_harmony/runs/gb3w5u96?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1da728790a0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"color_harmony\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"Classification\",\n",
    "    \"dataset\": \"Classification\",\n",
    "    \"epochs\": epochs,\n",
    "    \"alpha\": alpha,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, in_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residue = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x + residue\n",
    "    \n",
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        self.seq_modules = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(1024, 540)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq_modules(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_sensitive_crossentropy_loss(h, h_label, y):\n",
    "    cross_entropy = nn.CrossEntropyLoss()\n",
    "    ce_loss = cross_entropy(h, y)\n",
    "\n",
    "    num_unique = len(torch.unique(h_label))\n",
    "    return ce_loss + alpha * (1/num_unique - 1/4)*4**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classification().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-8)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "from custom_lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=2, eta_max=learning_rate,  T_up=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(train_loader):\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.train()\n",
    "    for data in tqdm(train_loader, total=len(train_loader), leave=False):\n",
    "        x = data['input_data'].to(device)\n",
    "        y = data['output_color'].to(dtype=torch.int64)\n",
    "\n",
    "        y_array = torch.eye(num_of_classes)[y].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "        correct_predictions += torch.any(top_predictions.to(\"cpu\") == y.view(-1, 1), dim=1).sum().item()\n",
    "        \n",
    "        loss = variance_sensitive_crossentropy_loss(output, top_predictions[:, 0], y_array)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    average_loss = train_loss / len(train_loader)\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def valid(valid_loader):\n",
    "    valid_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valid_loader, total=len(valid_loader), leave=False):\n",
    "            x = data['input_data'].to(device)\n",
    "            y = data['output_color'].to(dtype=torch.int64)\n",
    "\n",
    "            y_array = torch.eye(num_of_classes)[y].to(device)\n",
    "\n",
    "            output = model.forward(x)\n",
    "            \n",
    "            _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "            correct_predictions += torch.any(top_predictions.to(\"cpu\") == y.view(-1, 1), dim=1).sum().item()\n",
    "\n",
    "            loss = variance_sensitive_crossentropy_loss(output, top_predictions[:, 0], y_array)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    average_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "    return average_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 2\u001b[0m     t_loss, t_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# v_loss, v_acc = valid(valid_loader)\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[13], line 10\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m      7\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader), leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m     y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_color\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:441\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator\n\u001b[0;32m    440\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:388\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> 388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_MultiProcessingDataLoaderIter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:1042\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m   1035\u001b[0m w\u001b[38;5;241m.\u001b[39mdaemon \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m \u001b[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m   1039\u001b[0m \u001b[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m   1040\u001b[0m \u001b[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m   1041\u001b[0m \u001b[38;5;66;03m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m-> 1042\u001b[0m \u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1043\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index_queues\u001b[38;5;241m.\u001b[39mappend(index_queue)\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workers\u001b[38;5;241m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemon\u001b[39m\u001b[38;5;124m'\u001b[39m), \\\n\u001b[0;32m    119\u001b[0m        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdaemonic processes are not allowed to have children\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    120\u001b[0m _cleanup()\n\u001b[1;32m--> 121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sentinel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen\u001b[38;5;241m.\u001b[39msentinel\n\u001b[0;32m    123\u001b[0m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProcess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpopen_spawn_win32\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[1;32m--> 327\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     92\u001b[0m     reduction\u001b[38;5;241m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> 93\u001b[0m     \u001b[43mreduction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_child\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     set_spawning_popen(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdump\u001b[39m(obj, file, protocol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m     \u001b[43mForkingPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    t_loss, t_acc = train(train_loader)\n",
    "    # v_loss, v_acc = valid(valid_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    wandb.log({\"epoch\": epoch, \"learning rate\": optimizer.param_groups[0]['lr'], \"train loss\": t_loss, \"train accuracy\": t_acc})\n",
    "    # wandb.log({\"epoch\": epoch, \"learning rate\": optimizer.param_groups[0]['lr'], \"train loss\": t_loss, \"train accuracy\": t_acc, \"valid loss\": v_loss, \"valid accuracy\": v_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([264, 315,  35, 524], device='cuda:0')\n",
      "top_predictions: tensor([[264, 212, 272, 274],\n",
      "        [315, 213, 347, 231],\n",
      "        [ 35,  57, 517, 453],\n",
      "        [524,  83,  60,   2]], device='cuda:0'), label: tensor([332., 315.,  35., 524.])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = train_loader.__iter__().__next__()\n",
    "    x = sample['input_data'].to(device)\n",
    "    label = sample['output_color']\n",
    "\n",
    "    output = model.forward(x)\n",
    "\n",
    "    _, output_index = torch.max(output, 1)\n",
    "\n",
    "    _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "    print(f\"output: {output_index}\")\n",
    "    print(f\"top_predictions: {top_predictions}, label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "list_of_colors_path = r'C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\jsonl\\list_of_colors.jsonl'\n",
    "with open(list_of_colors_path, 'r') as list_of_colors_file:\n",
    "    list_of_colors_data = [json.loads(line) for line in list_of_colors_file]\n",
    "\n",
    "list_of_colors = [data['color_rgb'] for data in list_of_colors_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[64, 224, 208], [0, 86, 59], [13, 152, 186], [0, 109, 111]]\n",
      "[[100, 149, 237], [172, 225, 175], [39, 59, 226], [19, 136, 8]]\n",
      "[[255, 228, 225], [188, 143, 143], [139, 133, 137], [170, 152, 169]]\n",
      "[[42, 52, 57], [226, 88, 34], [250, 128, 114], [254, 111, 94]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    prediction_colors = [list_of_colors[c] for c in top_predictions[i]]\n",
    "    print(prediction_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 출력: 264 label: 332\n",
      "모델 출력: 315 label: 315\n",
      "모델 출력: 35 label: 35\n",
      "모델 출력: 524 label: 524\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(batch_size):\n",
    "    x_tmp = x[i][:12].cpu().detach().numpy().reshape((4,3))\n",
    "    label_tmp = list_of_colors[int(label.numpy()[i])]\n",
    "    output_tmp = list_of_colors[output_index[i]]\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 1)\n",
    "    plt.imshow([x_tmp])\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 2)\n",
    "    # plt.imshow([[output_tmp]])\n",
    "    prediction_colors = [list_of_colors[c] for c in top_predictions[i]]\n",
    "    plt.imshow([prediction_colors])\n",
    "    plt.axis(False)\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 3)\n",
    "    plt.imshow([[label_tmp]])\n",
    "    plt.axis(False)\n",
    "\n",
    "    print(\"모델 출력:\", output_index[i].item(), \"label:\", int(label.numpy()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\Model/model.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(\n",
       "  (seq_modules): Sequential(\n",
       "    (0): Linear(in_features=119, out_features=512, bias=True)\n",
       "    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       "  (out): Linear(in_features=1024, out_features=540, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kjk_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\datasets\\load.py:922: FutureWarning: The repository for Classification contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\\Classification.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (72030, 2), version: 1.1.1\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(path=r\"C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\", split=\"train\")\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_data\", \"output_color\"], dtype=torch.float32)\n",
    "print(f\"data: {dataset.shape}, version: {dataset.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_size: 50421, valid_size: 21609'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.7)\n",
    "valid_size = total_size - train_size\n",
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
    "f\"train_size: {train_size}, valid_size: {valid_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 540\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_loader.__iter__().__next__()\n",
    "input_size = sample['input_data'].shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "weight_path = r\"C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\jsonl\\class_weight.jsonl\"\n",
    "with open(weight_path, 'r') as path:\n",
    "    class_weight = json.load(path)\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = 1/class_weight/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "learning_rate = 0.001\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlifethis21\u001b[0m (\u001b[33mcolor_harmony\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\\wandb\\run-20240126_170541-urb2o27z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/color_harmony/color_harmony/runs/urb2o27z' target=\"_blank\">polished-energy-33</a></strong> to <a href='https://wandb.ai/color_harmony/color_harmony' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/color_harmony/color_harmony' target=\"_blank\">https://wandb.ai/color_harmony/color_harmony</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/color_harmony/color_harmony/runs/urb2o27z' target=\"_blank\">https://wandb.ai/color_harmony/color_harmony/runs/urb2o27z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/color_harmony/color_harmony/runs/urb2o27z?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x161afca6b80>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"color_harmony\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"Classification\",\n",
    "    \"dataset\": \"Classification\",\n",
    "    \"epochs\": epochs,\n",
    "    \"alpha\": alpha,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, in_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residue = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x + residue\n",
    "    \n",
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        self.seq_modules = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU()        )\n",
    "\n",
    "        self.out = nn.Linear(1024, 540)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq_modules(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_sensitive_crossentropy_loss(h, h_label, y):\n",
    "    cross_entropy = nn.CrossEntropyLoss()\n",
    "    ce_loss = cross_entropy(h, y)\n",
    "\n",
    "    num_unique = len(torch.unique(h_label))\n",
    "    return ce_loss + alpha * (1/num_unique - 1/4)*4**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classification().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-8)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "from custom_lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=2, eta_max=learning_rate,  T_up=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(train_loader):\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.train()\n",
    "    for data in tqdm(train_loader, total=len(train_loader), leave=False):\n",
    "        x = data['input_data'].to(device)\n",
    "        y = data['output_color'].to(dtype=torch.int64)\n",
    "\n",
    "        y_array = torch.eye(num_of_classes)[y].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "        correct_predictions += torch.any(top_predictions.to(\"cpu\") == y.view(-1, 1), dim=1).sum().item()\n",
    "        \n",
    "        loss = variance_sensitive_crossentropy_loss(output, top_predictions[:, 0], y_array)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    average_loss = train_loss / len(train_loader)\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def valid(valid_loader):\n",
    "    valid_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valid_loader, total=len(valid_loader), leave=False):\n",
    "            x = data['input_data'].to(device)\n",
    "            y = data['output_color'].to(dtype=torch.int64)\n",
    "\n",
    "            y_array = torch.eye(num_of_classes)[y].to(device)\n",
    "\n",
    "            output = model.forward(x)\n",
    "            \n",
    "            _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "            correct_predictions += torch.any(top_predictions.to(\"cpu\") == y.view(-1, 1), dim=1).sum().item()\n",
    "\n",
    "            loss = variance_sensitive_crossentropy_loss(output, top_predictions[:, 0], y_array)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    average_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "    return average_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 2\u001b[0m     t_loss, t_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     v_loss, v_acc \u001b[38;5;241m=\u001b[39m valid(valid_loader)\n\u001b[0;32m      4\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[16], line 14\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_data\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     12\u001b[0m y \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_color\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto(dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m---> 14\u001b[0m y_array \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_of_classes\u001b[49m\u001b[43m)\u001b[49m[y]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     16\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     17\u001b[0m output \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mforward(x)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    t_loss, t_acc = train(train_loader)\n",
    "    v_loss, v_acc = valid(valid_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    wandb.log({\"epoch\": epoch, \"learning rate\": optimizer.param_groups[0]['lr'], \"train loss\": t_loss, \"train accuracy\": t_acc, \"valid loss\": v_loss, \"valid accuracy\": v_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([272, 319, 202, 482], device='cuda:0')\n",
      "top_predictions: tensor([[272, 139,  79, 241],\n",
      "        [319, 516, 101,  27],\n",
      "        [202, 418, 350,  72],\n",
      "        [482, 202, 410, 150]], device='cuda:0'), label: tensor([272., 319., 202., 202.])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = train_loader.__iter__().__next__()\n",
    "    x = sample['input_data'].to(device)\n",
    "    label = sample['output_color']\n",
    "\n",
    "    output = model.forward(x)\n",
    "\n",
    "    _, output_index = torch.max(output, 1)\n",
    "\n",
    "    _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "    print(f\"output: {output_index}\")\n",
    "    print(f\"top_predictions: {top_predictions}, label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "list_of_colors_path = r'C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\jsonl\\list_of_colors.jsonl'\n",
    "with open(list_of_colors_path, 'r') as list_of_colors_file:\n",
    "    list_of_colors_data = [json.loads(line) for line in list_of_colors_file]\n",
    "\n",
    "list_of_colors = [data['color_rgb'] for data in list_of_colors_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13, 152, 186], [229, 170, 112], [255, 127, 80], [0, 73, 83]]\n",
      "[[21, 96, 189], [140, 146, 172], [255, 121, 0], [237, 41, 57]]\n",
      "[[243, 229, 171], [221, 160, 221], [204, 204, 255], [251, 206, 177]]\n",
      "[[227, 37, 107], [243, 229, 171], [197, 75, 140], [168, 28, 7]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    prediction_colors = [list_of_colors[c] for c in top_predictions[i]]\n",
    "    print(prediction_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 출력: 272 label: 272\n",
      "모델 출력: 319 label: 319\n",
      "모델 출력: 202 label: 202\n",
      "모델 출력: 482 label: 202\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(batch_size):\n",
    "    x_tmp = x[i][:12].cpu().detach().numpy().reshape((4,3))\n",
    "    label_tmp = list_of_colors[int(label.numpy()[i])]\n",
    "    output_tmp = list_of_colors[output_index[i]]\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 1)\n",
    "    plt.imshow([x_tmp])\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 2)\n",
    "    # plt.imshow([[output_tmp]])\n",
    "    prediction_colors = [list_of_colors[c] for c in top_predictions[i]]\n",
    "    plt.imshow([prediction_colors])\n",
    "    plt.axis(False)\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 3)\n",
    "    plt.imshow([[label_tmp]])\n",
    "    plt.axis(False)\n",
    "\n",
    "    print(\"모델 출력:\", output_index[i].item(), \"label:\", int(label.numpy()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\Model/model.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(\n",
       "  (seq_modules): Sequential(\n",
       "    (0): Linear(in_features=119, out_features=512, bias=True)\n",
       "    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (7): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (8): ReLU()\n",
       "  )\n",
       "  (out): Linear(in_features=1024, out_features=540, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kjk_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: (72030, 2), version: 1.1.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\datasets\\load.py:922: FutureWarning: The repository for Classification contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\\Classification.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(path=r\"C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\", split=\"train\")\n",
    "dataset.set_format(type=\"torch\", columns=[\"input_data\", \"output_color\"], dtype=torch.float32)\n",
    "print(f\"data: {dataset.shape}, version: {dataset.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_size: 50421, valid_size: 21609'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_size = len(dataset)\n",
    "train_size = int(total_size * 0.7)\n",
    "valid_size = total_size - train_size\n",
    "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
    "f\"train_size: {train_size}, valid_size: {valid_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_classes = 540\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
    "valid_loader = DataLoader(valid_data, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = train_loader.__iter__().__next__()\n",
    "input_size = sample['input_data'].shape[1]\n",
    "input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "weight_path = r\"C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\jsonl\\class_weight.jsonl\"\n",
    "with open(weight_path, 'r') as path:\n",
    "    class_weight = json.load(path)\n",
    "class_weight = torch.tensor(class_weight, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = 1/class_weight/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3000\n",
    "learning_rate = 0.001\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlifethis21\u001b[0m (\u001b[33mcolor_harmony\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\Classification\\wandb\\run-20240122_174715-oucfh8u0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/color_harmony/color_harmony/runs/oucfh8u0' target=\"_blank\">curious-waterfall-32</a></strong> to <a href='https://wandb.ai/color_harmony/color_harmony' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/color_harmony/color_harmony' target=\"_blank\">https://wandb.ai/color_harmony/color_harmony</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/color_harmony/color_harmony/runs/oucfh8u0' target=\"_blank\">https://wandb.ai/color_harmony/color_harmony/runs/oucfh8u0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/color_harmony/color_harmony/runs/oucfh8u0?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1da29c7b850>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"color_harmony\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"Classification\",\n",
    "    \"dataset\": \"Classification\",\n",
    "    \"epochs\": epochs,\n",
    "    \"alpha\": alpha,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, hidden_dim)\n",
    "        self.layer2 = nn.Linear(hidden_dim, in_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residue = x\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        return x + residue\n",
    "    \n",
    "class Classification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classification, self).__init__()\n",
    "        self.seq_modules = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.LayerNorm(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            ResBlock(1024, 2048),\n",
    "            nn.LayerNorm(1024),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(1024, 2048)\n",
    "        )\n",
    "\n",
    "        self.out = nn.Linear(1024, 540)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.seq_modules(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def variance_sensitive_crossentropy_loss(h, h_label, y):\n",
    "    cross_entropy = nn.CrossEntropyLoss()\n",
    "    ce_loss = cross_entropy(h, y)\n",
    "\n",
    "    num_unique = len(torch.unique(h_label))\n",
    "    return ce_loss + alpha * (1/num_unique - 1/4)*4**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classification().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-8)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)\n",
    "from custom_lr_scheduler import CosineAnnealingWarmUpRestarts\n",
    "\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, T_mult=2, eta_max=learning_rate,  T_up=3, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train(train_loader):\n",
    "    train_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.train()\n",
    "    for data in tqdm(train_loader, total=len(train_loader), leave=False):\n",
    "        x = data['input_data'].to(device)\n",
    "        y = data['output_color'].to(dtype=torch.int64)\n",
    "\n",
    "        y_array = torch.eye(num_of_classes)[y].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(x)\n",
    "        \n",
    "        _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "        correct_predictions += torch.any(top_predictions.to(\"cpu\") == y.view(-1, 1), dim=1).sum().item()\n",
    "        \n",
    "        loss = variance_sensitive_crossentropy_loss(output, top_predictions[:, 0], y_array)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        total_samples += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    average_loss = train_loss / len(train_loader)\n",
    "\n",
    "    return average_loss, accuracy\n",
    "\n",
    "\n",
    "def valid(valid_loader):\n",
    "    valid_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(valid_loader, total=len(valid_loader), leave=False):\n",
    "            x = data['input_data'].to(device)\n",
    "            y = data['output_color'].to(dtype=torch.int64)\n",
    "\n",
    "            y_array = torch.eye(num_of_classes)[y].to(device)\n",
    "\n",
    "            output = model.forward(x)\n",
    "            \n",
    "            _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "            correct_predictions += torch.any(top_predictions.to(\"cpu\") == y.view(-1, 1), dim=1).sum().item()\n",
    "\n",
    "            loss = variance_sensitive_crossentropy_loss(output, top_predictions[:, 0], y_array)\n",
    "            \n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            total_samples += y.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples * 100\n",
    "    average_loss = valid_loss / len(valid_loader)\n",
    "\n",
    "    return average_loss, accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[1;32m----> 2\u001b[0m     t_loss, t_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     v_loss, v_acc \u001b[38;5;241m=\u001b[39m valid(valid_loader)\n\u001b[0;32m      4\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[15], line 24\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_loader)\u001b[0m\n\u001b[0;32m     20\u001b[0m correct_predictions \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39many(top_predictions\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m y\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     22\u001b[0m loss \u001b[38;5;241m=\u001b[39m variance_sensitive_crossentropy_loss(output, top_predictions[:, \u001b[38;5;241m0\u001b[39m], y_array)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     26\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\mlfav\\anaconda3\\envs\\kjk_py39\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    t_loss, t_acc = train(train_loader)\n",
    "    v_loss, v_acc = valid(valid_loader)\n",
    "    scheduler.step()\n",
    "    \n",
    "    wandb.log({\"epoch\": epoch, \"learning rate\": optimizer.param_groups[0]['lr'], \"train loss\": t_loss, \"train accuracy\": t_acc, \"valid loss\": v_loss, \"valid accuracy\": v_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([216, 331,  57,  39], device='cuda:0')\n",
      "top_predictions: tensor([[216, 310, 333, 322],\n",
      "        [331, 165, 199, 252],\n",
      "        [ 57, 144, 163, 111],\n",
      "        [ 39,   4, 406,  47]], device='cuda:0'), label: tensor([216., 331.,  57.,  39.])\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample = train_loader.__iter__().__next__()\n",
    "    x = sample['input_data'].to(device)\n",
    "    label = sample['output_color']\n",
    "\n",
    "    output = model.forward(x)\n",
    "\n",
    "    _, output_index = torch.max(output, 1)\n",
    "\n",
    "    _, top_predictions = torch.topk(output, k=4, dim=1)\n",
    "    print(f\"output: {output_index}\")\n",
    "    print(f\"top_predictions: {top_predictions}, label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "list_of_colors_path = r'C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\color_classification\\jsonl\\list_of_colors.jsonl'\n",
    "with open(list_of_colors_path, 'r') as list_of_colors_file:\n",
    "    list_of_colors_data = [json.loads(line) for line in list_of_colors_file]\n",
    "\n",
    "list_of_colors = [data['color_rgb'] for data in list_of_colors_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210, 180, 140], [160, 120, 90], [193, 154, 107], [239, 223, 187]]\n",
      "[[230, 230, 250], [247, 247, 247], [185, 217, 235], [190, 191, 197]]\n",
      "[[219, 215, 210], [192, 192, 192], [85, 85, 85], [65, 74, 76]]\n",
      "[[0, 73, 83], [0, 35, 102], [0, 33, 71], [255, 117, 24]]\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size):\n",
    "    prediction_colors = [list_of_colors[c] for c in top_predictions[i]]\n",
    "    print(prediction_colors)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 출력: 216 label: 216\n",
      "모델 출력: 331 label: 331\n",
      "모델 출력: 57 label: 57\n",
      "모델 출력: 39 label: 39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for i in range(batch_size):\n",
    "    x_tmp = x[i][:12].cpu().detach().numpy().reshape((4,3))\n",
    "    label_tmp = list_of_colors[int(label.numpy()[i])]\n",
    "    output_tmp = list_of_colors[output_index[i]]\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 1)\n",
    "    plt.imshow([x_tmp])\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 2)\n",
    "    # plt.imshow([[output_tmp]])\n",
    "    prediction_colors = [list_of_colors[c] for c in top_predictions[i]]\n",
    "    plt.imshow([prediction_colors])\n",
    "    plt.axis(False)\n",
    "\n",
    "    plt.subplot(batch_size, 3, i * 3 + 3)\n",
    "    plt.imshow([[label_tmp]])\n",
    "    plt.axis(False)\n",
    "\n",
    "    print(\"모델 출력:\", output_index[i].item(), \"label:\", int(label.numpy()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\mlfav\\lib\\shlee\\Favorfit-Color-Recommendation\\Model/model.pt'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Classification(\n",
       "  (seq_modules): Sequential(\n",
       "    (0): Linear(in_features=119, out_features=512, bias=True)\n",
       "    (1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    (7): ResBlock(\n",
       "      (layer1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "    (8): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    (9): ReLU()\n",
       "    (10): ResBlock(\n",
       "      (layer1): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "      (layer2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (out): Linear(in_features=1024, out_features=540, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kjk_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
